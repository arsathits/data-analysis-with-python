{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aeb4eeb",
   "metadata": {},
   "source": [
    "# Ames Housing Data Cleaning\n",
    "\n",
    "## 1. Setup & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a867bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#constants\n",
    "DATA_PATH = Path(\"../dataset/train.csv\")\n",
    "CLEANED_DATA_PATH = Path(\"../dataset/cleaned_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329c89c",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Load Raw Data\n",
    "\n",
    "Loads the raw Ames Housing dataset from CSV.  \n",
    "Ensures you start with a fresh copy for cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b947d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw data: (1460, 81)\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data():\n",
    "    \"\"\"Load raw data from CSV file.\"\"\"\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Loaded raw data: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "df_raw = load_raw_data()\n",
    "df = df_raw.copy()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae4e7a",
   "metadata": {},
   "source": [
    "## ðŸ” Analyze Missing Values\n",
    "\n",
    "Summarizes missing values in each column, showing count, percentage, and data type.  \n",
    "Helps you understand where and how much data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df468c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values analysis:\n",
      "              missing_count  missing_percent missing_dtype\n",
      "PoolQC                 1453        99.520548        object\n",
      "MiscFeature            1406        96.301370        object\n",
      "Alley                  1369        93.767123        object\n",
      "Fence                  1179        80.753425        object\n",
      "MasVnrType              872        59.726027        object\n",
      "FireplaceQu             690        47.260274        object\n",
      "LotFrontage             259        17.739726       float64\n",
      "GarageType               81         5.547945        object\n",
      "GarageYrBlt              81         5.547945       float64\n",
      "GarageFinish             81         5.547945        object\n",
      "GarageQual               81         5.547945        object\n",
      "GarageCond               81         5.547945        object\n",
      "BsmtExposure             38         2.602740        object\n",
      "BsmtFinType2             38         2.602740        object\n",
      "BsmtQual                 37         2.534247        object\n",
      "BsmtCond                 37         2.534247        object\n",
      "BsmtFinType1             37         2.534247        object\n",
      "MasVnrArea                8         0.547945       float64\n",
      "Electrical                1         0.068493        object\n"
     ]
    }
   ],
   "source": [
    "def analyze_missing_values(df):\n",
    "    \"\"\"Analyze missing values in the DataFrame.\"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    missing_percent = (missing/len(df)) * 100\n",
    "\n",
    "    missing_df = pd.DataFrame({\n",
    "        'missing_count' : missing,\n",
    "        'missing_percent' : missing_percent,\n",
    "        'missing_dtype' : df.dtypes\n",
    "    })\n",
    "\n",
    "    missing_df = missing_df[missing_df['missing_count']>0].sort_values(by='missing_count', ascending=False)\n",
    "\n",
    "    return missing_df\n",
    "\n",
    "missing_values = analyze_missing_values(df)\n",
    "print(\"Missing values analysis:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23afa7c4",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Handle Missing Values\n",
    "\n",
    "Fills missing values using domain knowledge:\n",
    "- LotFrontage: median per Neighborhood\n",
    "- Numerical columns: median\n",
    "- Absence features: 'NA' or 'None'\n",
    "- Electrical: mode\n",
    "- Other categoricals: mode\n",
    "\n",
    "Ensures no missing values remain before further cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab646b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    \"\"\"Handle missing values in the DataFrame.\"\"\"\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # LotFrontage â†’ median per Neighborhood\n",
    "    if \"LotFrontage\" in df.columns:\n",
    "        df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "    \n",
    "    # Numerical â†’ median\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns    \n",
    "    for col in num_cols:\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Absence categories â†’ fill with 'NA'/'None'\n",
    "    absence_features = [\n",
    "    \"MasVnrType\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\n",
    "    \"BsmtFinType1\",\"BsmtFinType2\",\"GarageType\",\"GarageFinish\",\n",
    "    \"GarageQual\",\"GarageCond\",\"FireplaceQu\",\n",
    "    \"PoolQC\",\"Fence\",\"Alley\",\"MiscFeature\"]\n",
    "    \n",
    "    for col in absence_features:\n",
    "        if col in df.columns:\n",
    "            fill_value = 'None' if col == \"MasVnrType\" else \"NA\"\n",
    "            df[col] = df[col].fillna(fill_value)  # Removed inplace=True\n",
    "\n",
    "    # Electrical â†’ mode\n",
    "    if \"Electrical\" in df.columns and df['Electrical'].isnull().any():\n",
    "        df[\"Electrical\"] = df[\"Electrical\"].fillna(df[\"Electrical\"].mode()[0])  # Removed inplace=True\n",
    "\n",
    "    # Get all categorical columns as a set\n",
    "    all_cat_cols = set(df.select_dtypes(include=[\"object\"]).columns)\n",
    "    \n",
    "    # Remove already handled columns using set difference\n",
    "    remaining_cats = all_cat_cols - set(absence_features) - {\"Electrical\"}\n",
    "    \n",
    "    # Handle only the remaining categorical columns\n",
    "    for col in remaining_cats:\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950157c",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Fix Data Types\n",
    "\n",
    "Converts columns to appropriate numeric or datetime types.  \n",
    "Ensures calculations and transformations work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa894dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['LotFrontage', 'LotArea', 'MasVnrArea', 'GarageYrBlt']\n",
    "year_columns = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "def fix_datatypes(df):\n",
    "    \"\"\"Convert columns to appropriate datatypes\"\"\"\n",
    "    # Convert numeric columns that were read as object\n",
    "    for col in numeric_columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    #convert year columns to datetime\n",
    "    for col in year_columns:\n",
    "        df[col] = pd.to_datetime(df[col], format=\"%Y\", errors='coerce')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff01f47c",
   "metadata": {},
   "source": [
    "## ðŸš¨ Analyze Outliers\n",
    "\n",
    "Detects outliers in key numeric columns using z-score thresholds.  \n",
    "Reports count, percentage, and threshold values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd19ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTLIER_COLUMNS = [\n",
    "    'LotFrontage', 'LotArea', 'MasVnrArea',\n",
    "    'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF',\n",
    "    '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n",
    "    'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "    'SalePrice'\n",
    "]\n",
    "\n",
    "def analyze_outliers(df, OUTLIER_COLUMNS, n_std=3):\n",
    "\n",
    "    outliers_info = {}\n",
    "\n",
    "    for col in OUTLIER_COLUMNS:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        z_score = np.abs((df[col]-mean)/std)\n",
    "\n",
    "        outliers = df[z_score > n_std]\n",
    "\n",
    "        if len(outliers) > 0:\n",
    "            outliers_info[col]={\n",
    "                \"count\": len(outliers),\n",
    "                \"percent\": (len(outliers) / len(df)) * 100,\n",
    "                \"min\": df[col].min(),\n",
    "                \"max\": df[col].max(),\n",
    "                \"threshold_low\": mean - n_std * std,\n",
    "                \"threshold_high\": mean + n_std * std\n",
    "            }\n",
    "    \n",
    "    return pd.DataFrame(outliers_info).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe656e0a",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Handle Outliers\n",
    "\n",
    "Clips extreme values in specified columns to within defined thresholds.  \n",
    "Reduces the impact of outliers on modeling and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df2a5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom thresholds for specific columns\n",
    "COLUMN_THRESHOLDS = {\n",
    "    'LotArea': 2.5,        # More strict for lot area\n",
    "    'SalePrice': 2.5,      # More strict for price\n",
    "    'GrLivArea': 2.5,      # More strict for living area\n",
    "    'default': 3           # Default for other columns\n",
    "}\n",
    "\n",
    "def handling_outliers(df, columns, thresholds=COLUMN_THRESHOLDS, method='clip'):\n",
    "    df = df.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        n_std = thresholds.get(col, thresholds['default'])\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        \n",
    "        if method == 'clip':\n",
    "            df[col] = df[col].clip(\n",
    "                lower=mean - n_std * std,\n",
    "                upper=mean + n_std * std\n",
    "            )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f03b547",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Transform Skewed Features\n",
    "\n",
    "Identifies highly skewed numeric columns and applies log transformation (`log1p`).  \n",
    "Helps normalize distributions for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a44e37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_skewed(df, columns, skew_threshold=1):\n",
    "    \"\"\"\n",
    "    Transform skewed numerical features using log1p.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        columns: List of columns to check for skewness\n",
    "        skew_threshold: Above this value, apply transformation\n",
    "    \n",
    "    Returns:\n",
    "        df: Transformed DataFrame\n",
    "        transformed_cols: List of columns that were transformed\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate skewness for each column\n",
    "    skewness = df[columns].apply(lambda x: x.skew())\n",
    "    \n",
    "    # Find columns with high skewness\n",
    "    skewed_cols = skewness[skewness > skew_threshold].index.tolist()\n",
    "    \n",
    "    # Apply log1p transformation\n",
    "    for col in skewed_cols:\n",
    "        df[col] = np.log1p(df[col])\n",
    "        print(f\"Transformed {col}: skewness before={skewness[col]:.2f}, after={df[col].skew():.2f}\")\n",
    "    \n",
    "    return df, skewed_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6fcc3a",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save Cleaned Data\n",
    "\n",
    "Exports the fully cleaned dataset to CSV for modeling and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe6a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
